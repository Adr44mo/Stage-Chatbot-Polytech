# ğŸ§  Intelligent RAG System for Polytech Sorbonne

## ğŸ“‹ Description

SystÃ¨me RAG (Retrieval-Augmented Generation) intelligent pour le chatbot de Polytech Sorbonne. Ce systÃ¨me utilise un graphe LangGraph pour analyser l'intention des utilisateurs et router intelligemment vers diffÃ©rents types de traitement avec suivi complet des coÃ»ts et performances.

## ğŸ—ï¸ Architecture

### Composants principaux

1. **State Management** (`state.py`)
   - DÃ©finition des Ã©tats du graphe
   - Types d'intentions supportÃ©es (4 types)
   - Structures de donnÃ©es avec support historique

2. **Graph Nodes** (`nodes.py`)
   - `intent_analysis_node`: Analyse d'intention avec OpenAI (sortie JSON)
   - `direct_answer_node`: RÃ©ponses directes sans RAG
   - `document_retrieval_node`: RÃ©cupÃ©ration intelligente de documents
   - `rag_generation_node`: GÃ©nÃ©ration de rÃ©ponses avec contexte

3. **Graph Builder** (`graph.py`)
   - Construction du graphe LangGraph
   - Routage conditionnel basÃ© sur l'intention
   - Interface principale `invoke_intelligent_rag()`

4. **API Integration** (`api.py`)
   - Endpoints FastAPI compatibles avec l'API existante
   - ModÃ¨les Pydantic pour les requÃªtes/rÃ©ponses
   - Endpoints dÃ©taillÃ©s et simplifiÃ©s

5. **Token Tracking** (`token_tracker.py`)
   - Suivi dÃ©taillÃ© des coÃ»ts OpenAI
   - Calcul automatique par opÃ©ration
   - DÃ©tection dynamique du modÃ¨le (gpt-4o-mini)

6. **Advanced Logging** (`logger.py`)
   - Logs JSON structurÃ©s
   - Statistiques dÃ©taillÃ©es
   - Monitoring des performances

7. **Testing & CLI** (`cli.py`)
   - Tests automatisÃ©s
   - Interface en ligne de commande
   - Mode interactif

8. **Visualizations** (`visualizer.py`)
   - GÃ©nÃ©ration de graphiques de performance
   - Statistiques visuelles

## ğŸ¯ Types d'intentions

### DIRECT_ANSWER
- Salutations, remerciements
- Questions conversationnelles
- Pas de recherche documentaire

### RAG_NEEDED
- Questions factuelles sur Polytech
- Informations administratives, tÃ©moignages
- Recherche documentaire standard (documents gÃ©nÃ©raux)

### SYLLABUS_SPECIFIC_COURSE
- Questions sur un cours spÃ©cifique
- Objectifs pÃ©dagogiques, programme dÃ©taillÃ©
- Recherche ciblÃ©e dans les syllabus

### SYLLABUS_SPECIALITY_OVERVIEW
- Vue d'ensemble des cours d'une spÃ©cialitÃ©
- Tables des matiÃ¨res (TOC)
- Recherche par mÃ©tadonnÃ©es (`metadata.type=toc`, `metadata.specialite=XXX`)

## ğŸ“ SpÃ©cialitÃ©s Ã  Polytech Sorbonne

- **AGRAL**: Agroalimentaire
- **EISE**: Ã‰lectronique et Informatique - SystÃ¨mes EmbarquÃ©s
- **EI2I**: Ã‰lectronique et Informatique - Informatique Industrielle
- **GM**: GÃ©nie MÃ©canique
- **MAIN**: MathÃ©matiques AppliquÃ©es et Informatique
- **MTX**: MatÃ©riaux
- **ROB**: Robotique
- **ST**: Sciences de la Terre

## ğŸš€ Utilisation

### Dans le code

```python
from intelligent_rag.graph import invoke_intelligent_rag

# Utilisation simple
result = invoke_intelligent_rag("Quels sont les cours en MAIN ?")

# Avec historique
result = invoke_intelligent_rag(
    "Et les dÃ©bouchÃ©s ?", 
    chat_history=[
        {"role": "user", "content": "Parlez-moi de MAIN"},
        {"role": "assistant", "content": "MAIN est la spÃ©cialitÃ©..."}
    ]
)

print(result["answer"])
print(result["intent_analysis"]["intent"])
print(f"CoÃ»t: ${result['token_cost']['total_usd']:.4f}")
```

### API REST

#### Endpoints disponibles

```python
# Endpoint compatible avec l'API existante
POST /intelligent-rag/chat
{
  "prompt": "Quels sont les cours de robotique ?",
  "chat_history": []
}

# Endpoint dÃ©taillÃ© avec toutes les informations
POST /intelligent-rag/chat_detailed
{
  "prompt": "Peux-tu me parler des tÃ©moignages d'Ã©tudiants ?",
  "chat_history": []
}

# Statistiques du systÃ¨me
GET /intelligent-rag/statistics
GET /intelligent-rag/statistics/daily?date=2025-01-11

# SantÃ© du systÃ¨me
GET /intelligent-rag/health
```

#### IntÃ©gration avec l'API existante

```python
# Dans main.py
USE_INTELLIGENT_RAG = True  # Active le systÃ¨me intelligent

# L'endpoint /chat utilise automatiquement le systÃ¨me intelligent
POST /chat
{
  "prompt": "Question",
  "chat_history": []
}
```

### CLI

```bash
# Mode interactif
python -m Fastapi.backend.app.intelligent_rag.cli --mode interactive

# Mode batch
python -m Fastapi.backend.app.intelligent_rag.cli --mode batch --questions "Bonjour" "Cours MAIN" "Associations"

# Tests automatiques
python -m Fastapi.backend.app.intelligent_rag.cli --mode test
```

### CLI

```bash
# Mode interactif
python -m Fastapi.backend.app.intelligent_rag.cli --mode interactive

# Mode batch
python -m Fastapi.backend.app.intelligent_rag.cli --mode batch --questions "Bonjour" "Cours MAIN" "Associations"

# Tests automatiques
python -m Fastapi.backend.app.intelligent_rag.cli --mode test
```

## ğŸ’° Suivi des CoÃ»ts et Performances

### Token Tracking
- **CoÃ»t par opÃ©ration** : Analyse d'intention, gÃ©nÃ©ration de rÃ©ponse
- **ModÃ¨le auto-dÃ©tectÃ©** : gpt-4o-mini (prix actualisÃ©s)
- **Tokens dÃ©taillÃ©s** : Input/Output pour chaque appel OpenAI
- **CoÃ»t total** : Calcul automatique par conversation

### Exemple de rÃ©ponse avec coÃ»ts
```json
{
  "answer": "RÃ©ponse gÃ©nÃ©rÃ©e...",
  "token_cost": {
    "total_usd": 0.0234,
    "total_tokens": 156,
    "operations": [
      {
        "operation": "intent_analysis",
        "model": "gpt-4o-mini",
        "input_tokens": 12,
        "output_tokens": 0,
        "cost_usd": 0.0018
      },
      {
        "operation": "rag_generation", 
        "model": "gpt-4o-mini",
        "input_tokens": 120,
        "output_tokens": 24,
        "cost_usd": 0.0216
      }
    ]
  }
}
```

### Logs et Monitoring
- **Logs JSON** : Stockage dans `logs/responses/`
- **Statistiques** : AccÃ¨s via API `/intelligent-rag/statistics`
- **Monitoring** : Performances, erreurs, coÃ»ts par jour
- **Visualisations** : Graphiques automatiques (`visualizer.py`)

## ğŸ”§ FonctionnalitÃ©s avancÃ©es

### Analyse d'intention intelligente
- **Classification automatique** avec confiance > 95%
- **DÃ©tection de spÃ©cialitÃ©** et nom de cours
- **Gestion de l'historique** : DÃ©termine si le contexte est nÃ©cessaire
- **Fallback robuste** en cas d'erreur

### RÃ©cupÃ©ration de documents spÃ©cialisÃ©e

#### Pour les cours spÃ©cifiques
```python
# Recherche ciblÃ©e avec nom de cours
search_query = f"{course_name} {question}"
# Filtrage par tags: "cours", "syllabus"
```

#### Pour les vues d'ensemble de spÃ©cialitÃ©s
```python
# Recherche directe par mÃ©tadonnÃ©es
metadata_filter = {
    "metadata.type": "toc",
    "metadata.specialite": "ROB"  # SpÃ©cialitÃ© demandÃ©e
}
```

#### Pour les documents gÃ©nÃ©raux
```python
# RÃ©cupÃ©ration sans documents syllabus
# Recherche Ã©largie avec mots-clÃ©s contextuels
```

### Gestion intelligente de l'historique
- **DÃ©tection automatique** : `needs_history` dans l'analyse d'intention
- **Contexte sÃ©lectif** : Utilise seulement les 3 derniers Ã©changes
- **ContinuitÃ©** : RÃ©fÃ©rences aux messages prÃ©cÃ©dents


## ğŸ”— IntÃ©gration

### Avec l'API existante
```python
# Configuration dans main.py
USE_INTELLIGENT_RAG = True  # Active le systÃ¨me intelligent

# L'endpoint /chat utilise automatiquement le nouveau systÃ¨me
from intelligent_rag.api import router
app.include_router(router)
```

### Avec le systÃ¨me existant
```python
# Remplacement transparent
from intelligent_rag.graph import invoke_intelligent_rag

def chat_endpoint(question, history):
    result = invoke_intelligent_rag(question, history)
    return {
        "answer": result["answer"],
        "sources": result["sources"],
        "cost": result["token_cost"]
    }
```

## âš™ï¸ Configuration

### Variables d'environnement
```bash
export OPENAI_API_KEY="your_openai_key"
export USE_INTELLIGENT_RAG=true
```

### Configuration du systÃ¨me
```python
# Dans main.py
USE_INTELLIGENT_RAG = True   # SystÃ¨me intelligent (recommandÃ©)
USE_LANGGRAPH = True         # LangGraph RAG system 
# Si les deux sont False â†’ RAG classique
```

### Personnalisation
- **Prompts** : Modifier `nodes.py` pour ajuster les prompts
- **Intentions** : Adapter `state.py` pour de nouvelles intentions
- **Workflow** : Ã‰tendre `graph.py` pour de nouveaux nÅ“uds
- **CoÃ»ts** : Ajuster les prix dans `token_tracker.py`

## ğŸ“Š Monitoring et Statistiques

### MÃ©triques disponibles
- **Temps de traitement** par nÅ“ud et opÃ©ration
- **Taux de succÃ¨s** par intention
- **CoÃ»ts dÃ©taillÃ©s** par conversation et par jour
- **Utilisation des diffÃ©rents chemins** de traitement

### Logs structurÃ©s
```bash
# Structure des logs
logs/
â”œâ”€â”€ responses/          # Logs de conversations (JSON)
â”‚   â”œâ”€â”€ 20250111_143052_abc123.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ statistics/         # Stats journaliÃ¨res
â”‚   â”œâ”€â”€ daily_20250111.json
â”‚   â””â”€â”€ ...
â””â”€â”€ system.log         # Logs systÃ¨me
```

### Exemple de log de conversation
```json
{
  "session_id": "abc123",
  "timestamp": "2025-01-11T14:30:52",
  "request": {
    "question": "Quels sont les cours de ROB ?",
    "chat_history": []
  },
  "response": {
    "answer": "Voici les cours de Robotique...",
    "intent_analysis": {
      "intent": "SYLLABUS_SPECIALITY_OVERVIEW",
      "speciality": "ROB",
      "confidence": 0.95
    },
    "success": true
  },
  "performance": {
    "response_time_seconds": 2.34,
    "cost": {
      "total_usd": 0.0234,
      "operations": [...]
    }
  }
}
```

### Statistiques en temps rÃ©el
```bash
# Via API
GET /intelligent-rag/statistics

# RÃ©ponse
{
  "total_requests": 1234,
  "total_tokens": {"input": 45678, "output": 23456},
  "intents": {
    "RAG_NEEDED": 567,
    "SYLLABUS_SPECIALITY_OVERVIEW": 234,
    "SYLLABUS_SPECIFIC_COURSE": 123,
    "DIRECT_ANSWER": 89
  },
  "estimated_cost": {"total_usd": 12.34, "daily_usd": 2.45}
}
```

## ğŸ“ˆ Performance

### MÃ©triques clÃ©s
- **Temps de rÃ©ponse** : ~2-3 secondes
- **PrÃ©cision d'intention** : >95%
- **CoÃ»t par question** : ~$0.002-0.005
- **Documents rÃ©cupÃ©rÃ©s** : 8-12 par requÃªte

### Optimisations implÃ©mentÃ©es
- **Batch processing** pour la vectorisation
- **Filtrage par mÃ©tadonnÃ©es** pour les spÃ©cialitÃ©s
- **Recherche directe** pour les documents TOC
- **Cache des sessions** pour le tracking des coÃ»ts

## ğŸš€ Ã‰volutions futures

### ğŸ”„ Prochaines amÃ©liorations
- **Cache intelligent** des rÃ©sultats frÃ©quents
- **Apprentissage des prÃ©fÃ©rences** utilisateur
- **MÃ©triques de satisfaction** avec feedback
- **Optimisation des coÃ»ts** avec modÃ¨les moins chers pour certaines tÃ¢ches

### ğŸ¯ FonctionnalitÃ©s possibles
- **Support multi-langues** (anglais, franÃ§ais)
- **IntÃ©gration avec d'autres modÃ¨les** (Mistral, Claude)
- **Interface web dÃ©diÃ©e** pour les statistiques
- **API GraphQL** pour les requÃªtes complexes
- **SystÃ¨me de recommandations** basÃ© sur l'historique

### ğŸ“Š MÃ©triques avancÃ©es
- **A/B testing** entre diffÃ©rents prompts
- **Analyse de sentiment** des rÃ©ponses
- **DÃ©tection de questions similaires** pour optimisation
- **PrÃ©diction de l'intention** sans appel LLM

---

<div align="center">
  <sub>Construit avec â¤ï¸ pour amÃ©liorer l'expÃ©rience Ã©tudiante Ã  Polytech Sorbonne</sub>
</div>
