# üß† Intelligent RAG System for Polytech Sorbonne

## üìã Description

Syst√®me RAG (Retrieval-Augmented Generation) intelligent pour le chatbot de Polytech Sorbonne. Ce syst√®me utilise un graphe LangGraph pour analyser l'intention des utilisateurs et router intelligemment vers diff√©rents types de traitement avec suivi complet des co√ªts et performances.

## üèóÔ∏è Architecture

### Composants principaux

1. **State Management** (`state.py`)
   - D√©finition des √©tats du graphe
   - Types d'intentions support√©es (4 types)
   - Structures de donn√©es avec support historique

2. **Graph Nodes** (`nodes.py`)
   - `intent_analysis_node`: Analyse d'intention avec OpenAI (sortie JSON)
   - `direct_answer_node`: R√©ponses directes sans RAG
   - `document_retrieval_node`: R√©cup√©ration intelligente de documents
   - `rag_generation_node`: G√©n√©ration de r√©ponses avec contexte

3. **Graph Builder** (`graph.py`)
   - Construction du graphe LangGraph
   - Routage conditionnel bas√© sur l'intention
   - Interface principale `invoke_intelligent_rag()`

4. **API Integration** (`api.py`)
   - Endpoints FastAPI compatibles avec l'API existante
   - Mod√®les Pydantic pour les requ√™tes/r√©ponses
   - Endpoints d√©taill√©s et simplifi√©s

5. **Token Tracking** (`token_tracker.py`)
   - Suivi d√©taill√© des co√ªts OpenAI
   - Calcul automatique par op√©ration
   - D√©tection dynamique du mod√®le (gpt-4o-mini)

6. **Advanced Logging** (`logger.py`)
   - Logs JSON structur√©s
   - Statistiques d√©taill√©es
   - Monitoring des performances

7. **Testing & CLI** (`cli.py`)
   - Tests automatis√©s
   - Interface en ligne de commande
   - Mode interactif

8. **Visualizations** (`visualizer.py`)
   - G√©n√©ration de graphiques de performance
   - Statistiques visuelles

## üéØ Types d'intentions

### DIRECT_ANSWER
- Salutations, remerciements
- Questions conversationnelles
- Pas de recherche documentaire

### RAG_NEEDED
- Questions factuelles sur Polytech
- Informations administratives, t√©moignages
- Recherche documentaire standard (documents g√©n√©raux)

### SYLLABUS_SPECIFIC_COURSE
- Questions sur un cours sp√©cifique
- Objectifs p√©dagogiques, programme d√©taill√©
- Recherche cibl√©e dans les syllabus

### SYLLABUS_SPECIALITY_OVERVIEW
- Vue d'ensemble des cours d'une sp√©cialit√©
- Tables des mati√®res (TOC)
- Recherche par m√©tadonn√©es (`metadata.type=toc`, `metadata.specialite=XXX`)

## üéì Sp√©cialit√©s √† Polytech Sorbonne

- **AGRAL**: Agroalimentaire
- **EISE**: √âlectronique et Informatique - Syst√®mes Embarqu√©s
- **EI2I**: √âlectronique et Informatique - Informatique Industrielle
- **GM**: G√©nie M√©canique
- **MAIN**: Math√©matiques Appliqu√©es et Informatique
- **MTX**: Mat√©riaux
- **ROB**: Robotique
- **ST**: Sciences de la Terre

## üöÄ Utilisation

### Dans le code

```python
from intelligent_rag.graph import invoke_intelligent_rag

# Utilisation simple
result = invoke_intelligent_rag("Quels sont les cours en MAIN ?")

# Avec historique
result = invoke_intelligent_rag(
    "Et les d√©bouch√©s ?", 
    chat_history=[
        {"role": "user", "content": "Parlez-moi de MAIN"},
        {"role": "assistant", "content": "MAIN est la sp√©cialit√©..."}
    ]
)

print(result["answer"])
print(result["intent_analysis"]["intent"])
print(f"Co√ªt: ${result['token_cost']['total_usd']:.4f}")
```

### API REST

#### Endpoints disponibles

```python
# Endpoint compatible avec l'API existante
POST /intelligent-rag/chat
{
  "prompt": "Quels sont les cours de robotique ?",
  "chat_history": []
}

# Endpoint d√©taill√© avec toutes les informations
POST /intelligent-rag/chat_detailed
{
  "prompt": "Peux-tu me parler des t√©moignages d'√©tudiants ?",
  "chat_history": []
}

# Statistiques du syst√®me
GET /intelligent-rag/statistics
GET /intelligent-rag/statistics/daily?date=2025-01-11

# Sant√© du syst√®me
GET /intelligent-rag/health
```

#### Int√©gration avec l'API existante

```python
# Dans main.py
USE_INTELLIGENT_RAG = True  # Active le syst√®me intelligent

# L'endpoint /chat utilise automatiquement le syst√®me intelligent
POST /chat
{
  "prompt": "Question",
  "chat_history": []
}
```

### CLI

```bash
# Mode interactif
python -m Fastapi.backend.app.intelligent_rag.cli --mode interactive

# Mode batch
python -m Fastapi.backend.app.intelligent_rag.cli --mode batch --questions "Bonjour" "Cours MAIN" "Associations"

# Tests automatiques
python -m Fastapi.backend.app.intelligent_rag.cli --mode test
```

### CLI

```bash
# Mode interactif
python -m Fastapi.backend.app.intelligent_rag.cli --mode interactive

# Mode batch
python -m Fastapi.backend.app.intelligent_rag.cli --mode batch --questions "Bonjour" "Cours MAIN" "Associations"

# Tests automatiques
python -m Fastapi.backend.app.intelligent_rag.cli --mode test
```

## üí∞ Suivi des Co√ªts et Performances

### Token Tracking
- **Co√ªt par op√©ration** : Analyse d'intention, g√©n√©ration de r√©ponse
- **Mod√®le auto-d√©tect√©** : gpt-4o-mini (prix actualis√©s)
- **Tokens d√©taill√©s** : Input/Output pour chaque appel OpenAI
- **Co√ªt total** : Calcul automatique par conversation

### Exemple de r√©ponse avec co√ªts
```json
{
  "answer": "R√©ponse g√©n√©r√©e...",
  "token_cost": {
    "total_usd": 0.0234,
    "total_tokens": 156,
    "operations": [
      {
        "operation": "intent_analysis",
        "model": "gpt-4o-mini",
        "input_tokens": 12,
        "output_tokens": 0,
        "cost_usd": 0.0018
      },
      {
        "operation": "rag_generation", 
        "model": "gpt-4o-mini",
        "input_tokens": 120,
        "output_tokens": 24,
        "cost_usd": 0.0216
      }
    ]
  }
}
```

### Logs et Monitoring
- **Logs JSON** : Stockage dans `logs/responses/`
- **Statistiques** : Acc√®s via API `/intelligent-rag/statistics`
- **Monitoring** : Performances, erreurs, co√ªts par jour
- **Visualisations** : Graphiques automatiques (`visualizer.py`)

## üîß Fonctionnalit√©s avanc√©es

### Analyse d'intention intelligente
- **Classification automatique** avec confiance > 95%
- **D√©tection de sp√©cialit√©** et nom de cours
- **Gestion de l'historique** : D√©termine si le contexte est n√©cessaire
- **Fallback robuste** en cas d'erreur

### R√©cup√©ration de documents sp√©cialis√©e

#### Pour les cours sp√©cifiques
```python
# Recherche cibl√©e avec nom de cours
search_query = f"{course_name} {question}"
# Filtrage par tags: "cours", "syllabus"
```

#### Pour les vues d'ensemble de sp√©cialit√©s
```python
# Recherche directe par m√©tadonn√©es
metadata_filter = {
    "metadata.type": "toc",
    "metadata.specialite": "ROB"  # Sp√©cialit√© demand√©e
}
```

#### Pour les documents g√©n√©raux
```python
# R√©cup√©ration sans documents syllabus
# Recherche √©largie avec mots-cl√©s contextuels
```

### Gestion intelligente de l'historique
- **D√©tection automatique** : `needs_history` dans l'analyse d'intention
- **Contexte s√©lectif** : Utilise seulement les 3 derniers √©changes
- **Continuit√©** : R√©f√©rences aux messages pr√©c√©dents


## üîó Int√©gration

### Avec l'API existante
```python
# Configuration dans main.py
USE_INTELLIGENT_RAG = True  # Active le syst√®me intelligent

# L'endpoint /chat utilise automatiquement le nouveau syst√®me
from intelligent_rag.api import router
app.include_router(router)
```

### Avec le syst√®me existant
```python
# Remplacement transparent
from intelligent_rag.graph import invoke_intelligent_rag

def chat_endpoint(question, history):
    result = invoke_intelligent_rag(question, history)
    return {
        "answer": result["answer"],
        "sources": result["sources"],
        "cost": result["token_cost"]
    }
```

## ‚öôÔ∏è Configuration

### Variables d'environnement
```bash
export OPENAI_API_KEY="your_openai_key"
export USE_INTELLIGENT_RAG=true
```

### Configuration du syst√®me
```python
# Dans main.py
USE_INTELLIGENT_RAG = True   # Syst√®me intelligent (recommand√©)
USE_LANGGRAPH = True         # LangGraph RAG system 
# Si les deux sont False ‚Üí RAG classique
```

### Personnalisation
- **Prompts** : Modifier `nodes.py` pour ajuster les prompts
- **Intentions** : Adapter `state.py` pour de nouvelles intentions
- **Workflow** : √âtendre `graph.py` pour de nouveaux n≈ìuds
- **Co√ªts** : Ajuster les prix dans `token_tracker.py`

## üìä Monitoring et Statistiques

### M√©triques disponibles
- **Temps de traitement** par n≈ìud et op√©ration
- **Taux de succ√®s** par intention
- **Co√ªts d√©taill√©s** par conversation et par jour
- **Utilisation des diff√©rents chemins** de traitement

### Logs structur√©s
```bash
# Structure des logs
logs/
‚îú‚îÄ‚îÄ responses/          # Logs de conversations (JSON)
‚îÇ   ‚îú‚îÄ‚îÄ 20250111_143052_abc123.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ statistics/         # Stats journali√®res
‚îÇ   ‚îú‚îÄ‚îÄ daily_20250111.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ system.log         # Logs syst√®me
```

### Exemple de log de conversation
```json
{
  "session_id": "abc123",
  "timestamp": "2025-01-11T14:30:52",
  "request": {
    "question": "Quels sont les cours de ROB ?",
    "chat_history": []
  },
  "response": {
    "answer": "Voici les cours de Robotique...",
    "intent_analysis": {
      "intent": "SYLLABUS_SPECIALITY_OVERVIEW",
      "speciality": "ROB",
      "confidence": 0.95
    },
    "success": true
  },
  "performance": {
    "response_time_seconds": 2.34,
    "cost": {
      "total_usd": 0.0234,
      "operations": [...]
    }
  }
}
```

### Statistiques en temps r√©el
```bash
# Via API
GET /intelligent-rag/statistics

# R√©ponse
{
  "total_requests": 1234,
  "total_tokens": {"input": 45678, "output": 23456},
  "intents": {
    "RAG_NEEDED": 567,
    "SYLLABUS_SPECIALITY_OVERVIEW": 234,
    "SYLLABUS_SPECIFIC_COURSE": 123,
    "DIRECT_ANSWER": 89
  },
  "estimated_cost": {"total_usd": 12.34, "daily_usd": 2.45}
}
```

## üìà Performance

### M√©triques cl√©s
- **Temps de r√©ponse** : ~2-3 secondes
- **Pr√©cision d'intention** : >95%
- **Co√ªt par question** : ~$0.002-0.005
- **Documents r√©cup√©r√©s** : 8-12 par requ√™te

### Optimisations impl√©ment√©es
- **Batch processing** pour la vectorisation
- **Filtrage par m√©tadonn√©es** pour les sp√©cialit√©s
- **Recherche directe** pour les documents TOC
- **Cache des sessions** pour le tracking des co√ªts

## üöÄ √âvolutions futures

### üîÑ Prochaines am√©liorations
- **Cache intelligent** des r√©sultats fr√©quents
- **Apprentissage des pr√©f√©rences** utilisateur
- **M√©triques de satisfaction** avec feedback
- **Optimisation des co√ªts** avec mod√®les moins chers pour certaines t√¢ches

### üéØ Fonctionnalit√©s possibles
- **Support multi-langues** (anglais, fran√ßais)
- **Int√©gration avec d'autres mod√®les** (Mistral, Claude)
- **Interface web d√©di√©e** pour les statistiques
- **API GraphQL** pour les requ√™tes complexes
- **Syst√®me de recommandations** bas√© sur l'historique

### üìä M√©triques avanc√©es
- **A/B testing** entre diff√©rents prompts
- **Analyse de sentiment** des r√©ponses
- **D√©tection de questions similaires** pour optimisation
- **Pr√©diction de l'intention** sans appel LLM

---

<div align="center">
  <sub>Construit avec ‚ù§Ô∏è pour am√©liorer l'exp√©rience √©tudiante √† Polytech Sorbonne</sub>
</div>
