# Module Logic - Logique M√©tier

## Objectif

Ce module contient toute la logique m√©tier du pipeline de traitement :
- Classification automatique de documents
- Enrichissement de m√©tadonn√©es via IA
- Extraction et normalisation de donn√©es
- Validation par sch√©ma

## Structure

```
logic/
‚îú‚îÄ‚îÄ fill_logic.py      # Enrichissement automatique
‚îú‚îÄ‚îÄ detect_type.py     # Classification de documents
‚îú‚îÄ‚îÄ webjson.py         # Normalisation JSON web
‚îú‚îÄ‚îÄ load_pdf.py        # Extraction de contenu PDF
‚îú‚îÄ‚îÄ syllabus.py        # Traitement sp√©cialis√© syllabus
‚îî‚îÄ‚îÄ chunck_syll.py     # D√©coupage intelligent pour RAG
```

## fill_logic.py - Enrichissement Automatique

### Fonctions principales

#### `fill_missing_fields(data, fields, prompt_file)`
Enrichit automatiquement les champs manquants via IA.

```python
# Exemple d'usage
metadata = fill_missing_fields(
    data=document_data,
    fields=["title", "secteur", "auteurs"],
    prompt_file="globals/metadata.txt"
)
```

#### `validate_with_schema(data)`
Valide un document selon le sch√©ma JSON Polytech.

```python
is_valid = validate_with_schema(normalized_document)
if not is_valid:
    # Document rejet√©
```

#### `extract_json(response)`
Extrait et nettoie le JSON des r√©ponses IA.

```python
# G√®re les formats :
# ```json { "key": "value" } ```
# { "key": "value" }
clean_data = extract_json(ai_response)
```

### Pipeline d'Enrichissement
```mermaid
graph LR
    A[Document Brut] --> B[D√©tecter Type]
    B --> C[Enrichir M√©tadonn√©es]
    C --> D[Enrichir Tags]
    D --> E[Enrichir Type Sp√©cifique]
    E --> F[Valider]
    F --> G[Document Enrichi]
```

## detect_type.py - Classification

### Classification automatique
Identifie automatiquement le type de document parmi :
- **cours** : Mat√©riel p√©dagogique
- **projet** : Documents de projet
- **administratif** : Proc√©dures, r√®glements
- **specialite** : Information sur sp√©cialit√©s
- **vie_etudiante** : Activit√©s √©tudiantes
- **infrastructure** : Informations pratiques

```python
doc_type = detect_document_type(content)
# Retourne : "cours", "projet", "administratif", etc.
```

### Algorithme
1. **Analyse du contenu** (premiers 2000 caract√®res)
2. **Prompt IA sp√©cialis√©** pour classification
3. **Validation** du type retourn√©
4. **Fallback** en cas d'erreur

## webjson.py - Normalisation Web

### Normalisation d'entr√©es web
Convertit les donn√©es scrap√©es en format Polytech uniforme.

```python
normalized = normalize_entry(
    raw_data=scraped_json,
    chemin_local="/path/to/source",
    site_name="polytech_sorbonne"
)
```

### Transformations Appliqu√©es
- **Nettoyage du contenu** (HTML, caract√®res sp√©ciaux)
- **Extraction de m√©tadonn√©es** (titre, date, auteurs)
- **Normalisation des URLs**
- **Classification automatique**

## üìÑ load_pdf.py - Extraction PDF

### Types de PDFs Support√©s

#### PDFs Manuels
```python
result = process_manual_pdf_file(pdf_path)
# Extraction compl√®te + m√©tadonn√©es basiques
```

#### PDFs Scrap√©s
```python
result = process_scraped_pdf_file(pdf_path)
# Extraction + m√©tadonn√©es enrichies du scraping
```

### Extraction de Donn√©es
- **Texte complet** via PyMuPDF/pdfplumber
- **M√©tadonn√©es PDF** (auteur, titre, date)
- **Nettoyage automatique** (mise en forme, caract√®res)

## üéì syllabus.py - Traitement Syllabus

### Extraction Structur√©e
Traite sp√©cifiquement les documents syllabus pour extraire :
- **Structure hi√©rarchique** des cours
- **Informations p√©dagogiques** (cr√©dits, pr√©requis)
- **Planning d√©taill√©**
- **Comp√©tences vis√©es**

```python
syllabus_data = extract_syllabus_structure(pdf_path)
# Structure compl√®te du syllabus
```

## ‚úÇÔ∏è chunck_syll.py - D√©coupage RAG

### Chunking Intelligent
D√©coupe les syllabus de mani√®re optimale pour la recherche RAG :

```python
chunks = chunk_syllabus_for_rag(syllabus_data)
# Liste de chunks optimis√©s
```

### Strat√©gies de D√©coupage
1. **Respect de la structure** (cours, sections)
2. **Taille optimale** pour embeddings
3. **Pr√©servation du contexte** 
4. **M√©tadonn√©es enrichies** par chunk

## Utilisation

### Pipeline complet
```python
from logic.fill_logic import route_document
from logic.detect_type import detect_document_type

# 1. Classification
doc_type = detect_document_type(content)

# 2. Enrichissement complet
enriched_doc = route_document(raw_data)

# 3. Validation
is_valid = validate_with_schema(enriched_doc)
```

### Enrichissement cibl√©
```python
from logic.fill_logic import fill_missing_fields

# Enrichir seulement certains champs
tags = fill_missing_fields(
    data=document,
    fields=["tags"],
    prompt_file="globals/tags.txt"
)
```

## Bonnes pratiques

1. **Performance** : Cache les r√©ponses IA pour √©viter les appels redondants
2. **Robustesse** : Toujours valider les r√©ponses IA avant usage
3. **Monitoring** : Logger les temps de r√©ponse et taux de succ√®s
4. **Extensibilit√©** : Utiliser des prompts externalis√©s pour faciliter les ajustements

---
*Module de logique m√©tier int√©gr√© au pipeline New Filler (juillet 2025).*
