# ü§î D√©cisions Architecturales

Ce document explique les d√©cisions techniques importantes prises lors du d√©veloppement du syst√®me RAG Polytech, avec les raisons derri√®re chaque choix.

## üìã Table des Mati√®res

1. [Framework Backend](#framework-backend)
2. [Framework Frontend](#framework-frontend)
3. [Base de Donn√©es](#base-de-donn√©es)
4. [Syst√®me RAG](#syst√®me-rag)
5. [Authentification](#authentification)
6. [D√©ploiement](#d√©ploiement)
7. [Monitoring](#monitoring)

## üîß Framework Backend

### D√©cision : FastAPI
**Alternatives consid√©r√©es :** Django, Flask, Express.js

**Pourquoi FastAPI ?**
- **Performance** : Support natif async/await, plus rapide que Django/Flask
- **Documentation** : G√©n√©ration automatique OpenAPI/Swagger
- **Validation** : Pydantic pour validation de donn√©es robuste
- **√âcosyst√®me** : Int√©gration native avec LangChain
- **D√©veloppement** : Auto-reload en d√©veloppement, debugging facilit√©

**Inconv√©nients accept√©s :**
- √âcosyst√®me moins mature que Django
- Moins de packages tiers disponibles
- Courbe d'apprentissage pour l'async

```python
# Exemple : Validation automatique avec Pydantic
class ChatRequest(BaseModel):
    prompt: str = Field(..., min_length=1, max_length=1000)
    chat_history: List[ChatMessage] = Field(default=[], max_items=50)
    
# FastAPI g√©n√®re automatiquement la documentation
@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    return await process_chat(request)
```

## üé® Framework Frontend

### D√©cision : React + TypeScript
**Alternatives consid√©r√©es :** Vue.js, Angular, Svelte

**Pourquoi React ?**
- **√âcosyst√®me** : Large communaut√©, nombreux packages
- **Performance** : Virtual DOM, optimisations React 19
- **Flexibilit√©** : Pas d'opinions fortes sur la structure
- **Hiring** : Plus facile de trouver des d√©veloppeurs

**Pourquoi TypeScript ?**
- **S√©curit√©** : D√©tection d'erreurs √† la compilation
- **IDE** : Meilleure auto-compl√©tion et refactoring
- **Maintenabilit√©** : Code plus lisible et document√©
- **Int√©gration** : Excellent support avec React

```typescript
// Exemple : Typage strict des props
interface ChatProps {
  messages: Message[];
  onSendMessage: (message: string) => Promise<void>;
  isLoading: boolean;
}

const ChatComponent: React.FC<ChatProps> = ({ messages, onSendMessage, isLoading }) => {
  // TypeScript d√©tecte automatiquement les erreurs
  return <div>...</div>;
};
```

## üíæ Base de Donn√©es

### D√©cision : SQLite + ChromaDB
**Alternatives consid√©r√©es :** PostgreSQL, MySQL, MongoDB

**Pourquoi SQLite ?**
- **Simplicit√©** : Pas de serveur √† maintenir
- **Performance** : Excellent pour les lectures
- **Portabilit√©** : Fichier unique, facile √† sauvegarder
- **D√©veloppement** : Pas de configuration complexe

**Pourquoi ChromaDB ?**
- **Sp√©cialis√©** : Optimis√© pour les embeddings
- **Python-native** : Int√©gration directe avec LangChain
- **Simplicit√©** : Pas de configuration vectorielle complexe
- **Performance** : Recherche de similarit√© rapide

**Inconv√©nients accept√©s :**
- SQLite : Pas de concurrence en √©criture
- ChromaDB : √âcosyst√®me plus restreint que Pinecone

```python
# Exemple : Recherche vectorielle simple
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 12, "filter": {"specialite": "ROB"}}
)
docs = retriever.get_relevant_documents(query)
```

## üß† Syst√®me RAG

### D√©cision : LangGraph + Analyse d'Intention
**Alternatives consid√©r√©es :** RAG simple, Retrieval seul, Fine-tuning

**Pourquoi LangGraph ?**
- **Modularit√©** : Workflow composable en n≈ìuds
- **Debuggabilit√©** : √âtapes clairement d√©finies
- **Flexibilit√©** : Facilit√© d'ajout de nouvelles strat√©gies
- **Monitoring** : Suivi pr√©cis de chaque √©tape

**Pourquoi Analyse d'Intention ?**
- **Pr√©cision** : Strat√©gies adapt√©es au type de question
- **Performance** : √âvite les recherches inutiles
- **Exp√©rience** : R√©ponses plus pertinentes
- **√âvolutivit√©** : Facilit√© d'ajout de nouveaux types

```python
# Exemple : Workflow modulaire
workflow = StateGraph(RagState)
workflow.add_node("analyze_intent", analyze_intent)
workflow.add_node("retrieve_documents", retrieve_documents)
workflow.add_node("generate_answer", generate_answer)

workflow.add_edge(START, "analyze_intent")
workflow.add_conditional_edges(
    "analyze_intent",
    route_based_on_intent,
    {
        "direct": "generate_answer",
        "rag_needed": "retrieve_documents"
    }
)
```

### D√©cision : OpenAI GPT-4o-mini
**Alternatives consid√©r√©es :** GPT-4, Claude, LLaMA, Ollama local

**Pourquoi GPT-4o-mini ?**
- **Co√ªt** : 60x moins cher que GPT-4
- **Performance** : Suffisante pour nos cas d'usage
- **Vitesse** : R√©ponses plus rapides
- **Disponibilit√©** : Pas de liste d'attente

**Inconv√©nients accept√©s :**
- Capacit√© moindre que GPT-4 pour les t√¢ches complexes
- D√©pendance √† OpenAI

## üîê Authentification

### D√©cision : JWT + reCAPTCHA
**Alternatives consid√©r√©es :** Sessions, OAuth, Auth0

**Pourquoi JWT ?**
- **Stateless** : Pas de stockage serveur
- **Simplicit√©** : Facile √† impl√©menter
- **Flexibilit√©** : Fonctionne avec SPA
- **Standards** : Largement support√©

**Pourquoi reCAPTCHA ?**
- **Efficacit√©** : Bloque efficacement les bots
- **Gratuit** : Pas de co√ªts suppl√©mentaires
- **Int√©gration** : Facile √† int√©grer avec React

```python
# Exemple : G√©n√©ration JWT
def create_access_token(data: dict):
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt
```

## üöÄ D√©ploiement

### D√©cision : Docker + Nginx
**Alternatives consid√©r√©es :** Kubernetes, Serverless, VM classique

**Pourquoi Docker ?**
- **Consistance** : M√™me environnement dev/prod
- **Portabilit√©** : Fonctionne partout
- **Simplicit√©** : Plus simple que Kubernetes
- **Ressources** : Moins gourmand qu'une VM

**Pourquoi Nginx ?**
- **Performance** : Excellent pour les fichiers statiques
- **Fiabilit√©** : Tr√®s stable en production
- **Flexibilit√©** : Proxy, SSL, compression
- **Monitoring** : Logs d√©taill√©s

```dockerfile
# Exemple : Multi-stage build
FROM node:18-alpine as builder
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
```

## üìä Monitoring

### D√©cision : Logs + M√©triques Custom
**Alternatives consid√©r√©es :** Prometheus, Grafana, ELK Stack

**Pourquoi Logs Custom ?**
- **Simplicit√©** : Pas d'infrastructure complexe
- **Co√ªt** : Pas de services externes
- **Contr√¥le** : M√©triques exactement comme on les veut
- **D√©bogage** : Acc√®s direct aux donn√©es

**Pourquoi SQLite pour les m√©triques ?**
- **Coh√©rence** : M√™me base que l'application
- **Simplicit√©** : Pas de service suppl√©mentaire
- **Requ√™tes** : SQL familier pour les analyses
- **Backup** : Inclus dans la sauvegarde principale

```python
# Exemple : Tracking personnalis√©
@track_openai_call("intent_analysis")
def analyze_intent(state: RagState) -> RagState:
    # Le d√©corateur track automatiquement les tokens et co√ªts
    result = llm.invoke(prompt)
    return {"intent": result.content}
```

## üîÑ √âvolutions Futures

### D√©cisions Report√©es

**Microservices**
- **Pourquoi pas maintenant** : Complexit√© non justifi√©e
- **Quand** : Si > 10 d√©veloppeurs ou besoins sp√©cifiques
- **Comment** : S√©parer RAG, Auth, Frontend

**Base de Donn√©es Distribu√©e**
- **Pourquoi pas maintenant** : SQLite suffisant
- **Quand** : Si > 1000 utilisateurs concurrents
- **Comment** : Migration vers PostgreSQL + Redis

**Cache Avanc√©**
- **Pourquoi pas maintenant** : Performance acceptable
- **Quand** : Si latence > 3 secondes
- **Comment** : Redis pour cache embeddings

### D√©cisions Techniques Controvers√©es

**Pourquoi pas Pinecone ?**
- **Co√ªt** : 70$/mois vs gratuit ChromaDB
- **Complexit√©** : Configuration + API management
- **D√©pendance** : Vendor lock-in
- **Besoin** : Performance actuelle suffisante

**Pourquoi pas Next.js ?**
- **SSR** : Pas n√©cessaire pour une SPA
- **Complexit√©** : Vercel dependency
- **√âquipe** : Plus famili√®re avec React seul
- **Besoin** : CSR suffit pour le cas d'usage

**Pourquoi pas Kubernetes ?**
- **Ressources** : Trop gourmand pour un petit projet
- **Complexit√©** : Courbe d'apprentissage √©lev√©e
- **Besoin** : Docker Compose suffit
- **√âquipe** : Pas d'expertise DevOps avanc√©e

## üéØ M√©triques de D√©cision

### Crit√®res Principaux

1. **Simplicit√©** : Privil√©gier la solution la plus simple
2. **Maintenabilit√©** : Code facile √† modifier
3. **Performance** : Temps de r√©ponse < 3s
4. **Co√ªt** : Budget limit√© √©tudiant
5. **Apprentissage** : Technos connues de l'√©quipe

### Compromis Accept√©s

**Performance vs Simplicit√©**
- SQLite au lieu de PostgreSQL
- Accepter quelques millisecondes de plus pour √©viter la complexit√©

**Fonctionnalit√©s vs Temps**
- RAG intelligent au lieu de fine-tuning
- Analyse d'intention au lieu de ML complexe

**Co√ªt vs Performance**
- GPT-4o-mini au lieu de GPT-4
- ChromaDB au lieu de Pinecone

## üìö Ressources & R√©f√©rences

### Documentation Consult√©e
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [LangChain Documentation](https://langchain.readthedocs.io/)
- [OpenAI API Reference](https://platform.openai.com/docs)
- [ChromaDB Documentation](https://docs.trychroma.com/)

### Benchmarks R√©alis√©s
- **FastAPI vs Django** : 2x plus rapide pour les API
- **ChromaDB vs Pinecone** : Performance similaire, co√ªt 70x moins cher
- **GPT-4o-mini vs GPT-4** : Qualit√© acceptable, co√ªt 60x moins cher

### Retours d'Exp√©rience
- **Complexit√©** : LangGraph initialement d√©routant mais payant
- **Performance** : SQLite surprenant en lecture
- **D√©veloppement** : TypeScript ralentit au d√©but mais acc√©l√®re apr√®s

---

Ces d√©cisions peuvent √©voluer selon les besoins futurs du projet. L'important est de documenter le raisonnement pour les futures √©quipes.
